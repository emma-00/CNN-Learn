{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emma-00/CNN-Learn/blob/main/CNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch torchvision matplotlib numpy pandas"
      ],
      "metadata": {
        "id": "Wv-0UUzAVXhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe6e0a8a-9aca-4dfb-bf44-1b706ba80020"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h1>*`Step 1: Setup and Imports`*</h1>**\n",
        "\n",
        "\n",
        "**1. Import the necessary libraries:**"
      ],
      "metadata": {
        "id": "63h20PdVVmLk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lStwWYGLVNZE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h1>*`Step 2: Load and Explore the MNIST Dataset`*</h1>**\n",
        "\n",
        "\n",
        "**1. Define transformations to normalize the data:**\n",
        "\n",
        "Transformations are used to preprocess the dataset.\n",
        "\n",
        "The ToTensor transformation converts image data (which is typically in the form of a NumPy array or PIL image) into a PyTorch tensor.\n",
        "\n",
        "Normalize scales pixel values from the range [0, 255] to [0, 1]\n",
        "\n",
        "In PyTorch, normalization is applied using the formula:\n",
        "\n",
        "$$\n",
        "\\text{Normalized Value} = \\frac{\\text{Value} - \\text{Mean}}{\\text{Standard Deviation}}\n",
        "$$\n",
        "\n",
        "Values centered around 0 reduce difficulties with a range (-1, 1) in gradient computations, increases stability.\n"
      ],
      "metadata": {
        "id": "9mbvW1n7WbUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n"
      ],
      "metadata": {
        "id": "8JOdZM-dVWZe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating datasets:**"
      ],
      "metadata": {
        "id": "tOwBJfSuXBzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n"
      ],
      "metadata": {
        "id": "jPOBjSwkXLTE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10b9fd04-e3fe-4b85-bb78-1caa498912eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.30MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 154kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Create DataLoaders for batch processing:**\n",
        "\n",
        "DataLoader handles batch processing by grouping data samples into batches of the specified size. It also shuffles the data if required.\n",
        "\n",
        "**Why?**\n",
        "\n",
        "* Neural networks often process large datasets. Loading the entire dataset into memory is impractical.\n",
        "\n",
        "* Computing gradients for the entire dataset in a single forward and backward pass is computationally expensive and slow.\n",
        "\n",
        "* If a single sample is used for gradient updates, it can lead to noisy updates that overfit the training data.\n",
        "\n",
        "* Modern hardware (like GPUs) is optimized for parallel computations.By using batches, multiple samples can be processed simultaneously, taking full advantage of the hardware."
      ],
      "metadata": {
        "id": "dR5qhiujXTZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "wdFn82JoXOhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Visualize a few training samples:**\n",
        "\n",
        "We visualize a few samples to confirm that the data is loaded correctly.\n"
      ],
      "metadata": {
        "id": "OA4VGj7vZYjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_samples(data_loader):\n",
        "    data_iter = iter(data_loader)\n",
        "    images, labels = next(data_iter)\n",
        "    images = images[:8]\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    for i in range(8):\n",
        "        plt.subplot(1, 8, i + 1)\n",
        "        plt.imshow(images[i][0], cmap='gray')\n",
        "        plt.title(f\"Label: {labels[i]}\")\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_samples(train_loader)\n"
      ],
      "metadata": {
        "id": "T41djysFZUCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h1>*`Step 3: Define the CNN Model`*</h1>**\n",
        "\n",
        "\n",
        "**1. Build a simple CNN:**"
      ],
      "metadata": {
        "id": "VkHe2HBLZ1_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)  # Input layer to hidden layer\n",
        "        self.fc2 = nn.Linear(128, 10)       # Hidden layer to output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)  # Flatten the input image\n",
        "        x = F.relu(self.fc1(x))  # Apply ReLU activation\n",
        "        x = self.fc2(x)          # Output layer\n",
        "        return F.log_softmax(x, dim=1)  # Apply log-softmax for classification\n"
      ],
      "metadata": {
        "id": "qE7ZO6TdZ9Jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h1>*`Step 4: Train the CNN`*</h1>**\n",
        "\n",
        "\n",
        "**1. Initialize the model, loss function, and optimizer:**"
      ],
      "metadata": {
        "id": "JAbIv9EaaE7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = SimpleNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "I3cIgIk0Z_Iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Define the training loop:**\n"
      ],
      "metadata": {
        "id": "CRaKsxWCaP5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "id": "8ieBd8B-aUbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Train the model:**"
      ],
      "metadata": {
        "id": "HFx-ywrEai8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, criterion, optimizer, epochs=5)\n"
      ],
      "metadata": {
        "id": "7O__vTGIab34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h1>*`Step 5: Evaluate the Model`*</h1>**\n",
        "\n",
        "\n",
        "**1. Define the evaluation loop:**"
      ],
      "metadata": {
        "id": "fsfnBY4FwB-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total * 100\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy\n",
        "\n",
        "evaluate_model(model, test_loader)\n"
      ],
      "metadata": {
        "id": "PtCWCFQ_awgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h1>*`Step 6: Visualize Predictions`*</h1>**\n",
        "\n",
        "\n",
        "**1. Visualize predictions on test data:**"
      ],
      "metadata": {
        "id": "6YCyYLkFwlT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_predictions(model, test_loader):\n",
        "    model.eval()\n",
        "    data_iter = iter(test_loader)\n",
        "    images, labels = next(data_iter)\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    for i in range(8):\n",
        "        plt.subplot(1, 8, i + 1)\n",
        "        plt.imshow(images[i].cpu().squeeze(), cmap='gray')\n",
        "        plt.title(f\"P: {predicted[i].item()}\\nT: {labels[i].item()}\")\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_predictions(model, test_loader)\n"
      ],
      "metadata": {
        "id": "jAgUoZ6XweG0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}